---
title: "Imitator Developmental Series analysis"
author: "Adam Stuckert"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document: default
  pdf_document: default
---

```{r global_options, include=FALSE}
# load packages required for analyses
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
# library(biomaRt)
library(sleuth)
library(dplyr)
library(foreach)
library(doParallel)
library(data.table)
library(splines)
library(ggthemes)
library(scales)
library(gridExtra)
```

#### Background ####
This file should be run after This uses the pseudo-quantifications from Kallisto to undergo differential expression analyses. These pseudo-quantification results should be in a folder entitled "kallisto_quants" within the R project folder. 

Print R information so that I can easily pick out information for publication.

```{r}
sessionInfo()
```

```{r}
# memory.size() #clearly insu-fucking-ficient 

# 100% only leaving the above in for posterity.

# Jack up the memory alloted to R...this requires quite a bit
memory.limit(32000000)

# get the directory/path for each sample in this study
base_dir <- getwd()
# name of each sample
sample_id <- dir(file.path(base_dir, "kallisto_quants"))
# append them to get the location of each samples' quantification
kal_dirs <- sapply(sample_id, function(id) file.path(base_dir, "kallisto_quants", id))
# read in a tab-delimited file with information about samples and treatments
samples <- read.table("devel-sleuth-full.txt", header = TRUE)
# order them to match up with sample paths
samples <- samples[order(samples$sample),]
# combine into a single combined factor
group <- factor(paste(samples$locality,samples$week,sep="_"))
# bind this to the sample information dataframe
samples <- cbind(samples,group=group)
# append paths to the sample dataframe
samples <- dplyr::mutate(samples, path = kal_dirs)
# print to verify everything is copacetic
# now listen to Local H's "Bound for the floor"
samples

```


The above are all the samples in the dataset.


Now I have the path to each sample in the samples dataframe, as well as the path to the quantifications. Time to run the actual analyses. Building the model takes some time...


```{r}
#First, prepare the model by building the design; these need to be in numeric format
week <- samples$week
week <- as.numeric(week)
lane <- samples$lane
spline_design <- model.matrix(formula( ~ ns(week, df = 3) + lane))
spline_design

# import everything into a sleuth object using the Sleuth package, this takes a while and should leave a large object (>1gb, dependent on quantity of data)
so <- sleuth_prep(samples, num_cores = 6) 
```


Plot the PCA to see how samples fall out by time point and population. 

```{r}
plot_pca(so, units = "tpm", point_size = 0.001) + geom_point() + aes(size = 3, colour = samples$locality, shape = factor(samples$week)) + scale_colour_manual(values = c("yellow2","orange1", "chartreuse4", "red1"), guide = guide_legend(title = "Population", override.aes = list(size=4))) + scale_shape_manual(values=c(15,16,17,18), guide = guide_legend(title = "Timepoint (weeks)", override.aes = list(size=4))) + guides(size=FALSE)

# save the pca to local disk
ggsave("pca-subsamp-spline-tpm.pdf")
ggsave("pca-subsamp-spline-tpm.tiff", width = 6.81, height = 3.99)
```

```{r}
plot_pca(so, point_size = 0.001) + geom_point() + aes(size = 3, colour = samples$locality, shape = factor(samples$week)) + scale_colour_manual(values = c("yellow2","orange1", "chartreuse4", "red1"), guide = guide_legend(title = "Population", override.aes = list(size=4))) + scale_shape_manual(values=c(15,16,17,18), guide = guide_legend(title = "Timepoint (weeks)", override.aes = list(size=4))) + guides(size=FALSE)

ggsave("pca-subsamp-spline.pdf")
ggsave("pca-subsamp-spline.tiff", width = 6.81, height = 3.99)
```

This is a nice looking PCA, and it seems like we are getting things falling out in PC1 by time point and PC2 by morph, which is really phenomenal.



Odd, one of the Sauce 8 week tadpoles seems to be a clear outlier...which one is that?

```{r}
plot_pca(so, units = "tpm", point_size = 0.001, text_labels = TRUE) 
```

Alright, so S2-8 is the clear outlier here. At the end of all of this, I might reanalyze this data without that particular sample. For now, diagnose what is driving this as an 'outlier.'

```{r}
plot_loadings(so, pc_input = 1)
# plot(so, 'Transcript_20603', color_by = 'genotype')
ggsave("subsamp-spline-pc1-loadings.tiff", width = 6.81, height = 3.99)
```


Anyway, look at PC2, which should be population...


```{r}
plot_loadings(so, pc_input = 2)
# plot(so, 'Transcript_20603', color_by = 'genotype')
ggsave("subsamp-spline-pc2-loadings.tiff", width = 6.81, height = 3.99)

```

```{r}
# pull in the annotation information.
### Load the annotation data
# Import Xenopus information, select only peptides and gene columns, rename them
x2g <- fread("annotationmappingdocuments/xenpep2gene.tsv", header = FALSE)
x2g <- x2g[,-1]
colnames(x2g) <- c("peptide_id", "gene_name")

# Import Nanorana information, select only peptides and gene columns, rename them
n2g <- fread("annotationmappingdocuments/nan2gene.tsv", header = FALSE)
colnames(n2g) <- c("peptide_id", "gene_name")

# Import Uniref information, select only peptides and gene columns, rename them
u2g <- fread("annotationmappingdocuments/uniprot.tab", header = TRUE)
u2g <- u2g[,c(1,5)]
u2g$peptide_id <- ""
u2g$peptide_id <- paste("UniRef90_", u2g$Entry)
u2g <- u2g[,c(3,2)]
colnames(u2g) <- c("peptide_id", "gene_name")

# merge all three of those into one dataframe
a2g <- rbind(x2g, n2g, u2g)


# Annotation results from the full annotation database annotation
ann <- read.table("subimiallpep_tophit.txt", header = FALSE, fill = TRUE)
colnames(ann)[c(1:12)] <- c("transcript_id", "peptide_id", "percentage_id_matches",
                              "alignment_length", "number_mismatches", "number_gap_openings",
                              "query_start", "query_end", "alignment_start", "alignment_end",
                              "expected_value", "bitscore")
ann <- ann[,c(1:2,11)]

ann <- dplyr::left_join(ann, a2g, by = "peptide_id")
colnames(ann) <- c("target_id", "full_peptide_id", "full_evalue", "full_gene_name")

# Annotation results from the Xenopus only database annotation
xen <- read.table("subimixen_tophit.txt", header = FALSE, fill = TRUE)
colnames(xen)[c(1:12)] <- c("transcript_id", "peptide_id", "percentage_id_matches",
                              "alignment_length", "number_mismatches", "number_gap_openings",
                              "query_start", "query_end", "alignment_start", "alignment_end",
                              "expected_value", "bitscore")

xen <- xen[,c(1:2,11)]

# Merge the two different annotations
xen <- dplyr::left_join(xen, a2g, by = "peptide_id")
colnames(xen) <- c("target_id", "xen_peptide_id", "xen_evalue", "xen_gene_name")

anno <- dplyr::left_join(ann, xen, by = "target_id")


```

Analyze for differential expression between timepoints. 

```{r}

# Actual differential expressin analyses
samples$week <- as.factor(samples$week)

# Prepare the sleuth object again, but this time we are including our annotation information via target_mapping
so <- sleuth_prep(samples,  num_cores = 6, target_mapping = anno)

# load the full model, which includes a spline of time + the lane samples were sequenced on
so <- sleuth_fit(so, formula = spline_design, fit_name = "full") # changed from spline_design
# load the reduced model, this is only the lane samples were sequenced on
so <- sleuth_fit(so, formula = ~ lane, fit_name = "reduced")

# print the models
models(so)

# run a likelihood ratio test between the full and reduced models. This basically tests whether the inclusion of the time points explains the data better than the reduced model with just the lane. Transcripts better explained by the inclusion of time should be considered differentially expressed over time. Qvalues are corrected for multiple comparisons.
so_lrt <- sleuth_lrt(so, "reduced", "full")

# save the model results to a data frame
lrt_results <- sleuth_results(so_lrt, 'reduced:full', test_type = 'lrt')

# how many transcripts are differentially expressed if we use a cut off of a = 0.05?
table(lrt_results[,"qval"] < 0.05)

# order results by q value, then filter out only the significant ones
sig_results <-  lrt_results[order(lrt_results$qval),]
siggies <- sig_results[ which(sig_results$qval < 0.05),]

# a priori candidate color gene database
colors <- read.csv("color_genes.csv")
colnames(colors)[1] <- "gene_name"

# Make them all lower case...
colors$gene_name <- tolower(colors$gene_name)
lrt_results$full_gene_name <- tolower(lrt_results$full_gene_name)
lrt_results$xen_gene_name <- tolower(lrt_results$xen_gene_name)

## search through the results for anything that annotated in the full or xenopus annotation to a color gene
lrt_colors <- lrt_results %>% filter(full_gene_name %in% colors$gene_name | xen_gene_name %in% colors$gene_name)

## Alphabetize
lrt_colors <-  lrt_colors[order(lrt_colors$full_gene_name),]

## These are just the 'statistically significant' hits
lrt_colors <- dplyr::filter(lrt_colors, qval < 0.05)

##### This will iterate through and make a nice figure for each of the statistically significant color genes
# make sure that you have already made a folder called "colorgenespline-figures/" or it won't work ( you can do this in R too)
for (i in 1:nrow(lrt_colors)){
  transcript <- lrt_colors[i,"target_id"]
  gene <- lrt_colors[i,"xen_gene_name"]
  qval <- lrt_colors[i,"qval"]
  tmp <- so$obs_norm %>% dplyr::filter(target_id == transcript)  ### These are normalized values I think!
  tmp <- dplyr::full_join(so$sample_to_covariates, tmp, by = 'sample')
  tmp
  
  
a <- ggplot(tmp, aes(x=week, y=est_counts)) + geom_point(aes(size = 3, color = locality)) + scale_colour_manual(values = c("yellow2","orange1", "chartreuse4", "red1"), guide = guide_legend(title = "Population", override.aes = list(size=4))) +  geom_smooth(method = loess) + ggtitle(paste0(gene, "\n(", transcript, "), q value = ", qval)) + guides(size=FALSE) + theme_bw()
 

  ggsave(paste0("colorgenespline-figures/", gene, "-", transcript, ".png"), width = 6.81, height = 3.99)
}

# save results to spreadsheets
write.csv(lrt_colors, "imitator_significant_color_gene_stats.csv")
write.csv(siggies, "imitator_time_significant_genes.csv")

# get gene names for downstream GO analyses and save them
GO_siggies <- dplyr::filter(siggies, full_gene_name != "NA")
write.csv(GO_siggies, "imitator_significant_genes_GO.csv")


dim(lrt_colors)
unique_lrt_colors <- unique(lrt_colors$gene_name)

# walds tests between time points
so <- sleuth_wt(so, '(Intercept)')
so <- sleuth_wt(so, 'ns(week, df = 3)1')
so <- sleuth_wt(so, 'ns(week, df = 3)2')
so <- sleuth_wt(so, 'ns(week, df = 3)3')
week2walds <- sleuth_results(so, '(Intercept)', test_type = "wt", which_model = "full",
  rename_cols = TRUE, show_all = TRUE)

# splinetable <- kallisto_table(so)
```

11,646 DE transcripts accounting for batch effects.


Now I will functionally do the same thing as I did using the 4 time points, but now by each population instead.


```{r}
# population
# first prep the population matrix
#pop_design <- model.matrix(~0 + samples$locality)
#colnames(pop_design) <- levels(samples$locality)



sopop <- sleuth_prep(samples, num_cores = 6, target_mapping = anno)

sopop <- sleuth_fit(sopop, formula = ~ locality + lane, fit_name = "full")
sopop <- sleuth_fit(sopop, formula = ~ lane, fit_name = "reduced")
#so <- sleuth_fit(so, full_model = spline_design)
models(sopop)
pop_lrt <- sleuth_lrt(sopop, "reduced", "full")
# so_wt <- sleuth_wt(so, "reduced", "full")
# Ok I don't know why that doesn't actually work....

pop_lrt_results <- sleuth_results(pop_lrt, 'reduced:full', test_type = 'lrt')
table(pop_lrt_results[,"qval"] < 0.05) #9701 significant transcripts between the null and the others...
pop_lrt_results$full_gene_name <- tolower(pop_lrt_results$full_gene_name)
pop_lrt_results$xen_gene_name <- tolower(pop_lrt_results$xen_gene_name)

pop_sig_results <-  pop_lrt_results[order(pop_lrt_results$qval),]
pop_siggies <- pop_sig_results[ which(pop_sig_results$qval < 0.05),]

pop_lrt_colors <- pop_lrt_results %>% filter(full_gene_name %in% colors$gene_name | xen_gene_name %in% colors$gene_name)


## Alphabetize
pop_lrt_colors <-  pop_lrt_colors[order(pop_lrt_colors$full_gene_name),]


## These are just the 'statistically significant' hits
pop_lrt_colors <- dplyr::filter(pop_lrt_colors, qval < 0.05)



##### This will iterate through and make a nice figure for each of the statistically significant color genes
for (i in 1:nrow(pop_lrt_colors)){
  transcript <- pop_lrt_colors[i,"target_id"]
  gene <- pop_lrt_colors[i,"xen_gene_name"]
  qval <- pop_lrt_colors[i,"qval"]
  tmp <- sopop$obs_norm %>% dplyr::filter(target_id == transcript)  ### These are normalized values I think!
  tmp <- dplyr::full_join(sopop$sample_to_covariates, tmp, by = 'sample')
  tmp
  
  
a <- ggplot(tmp, aes(x=week, y=est_counts)) + geom_point(aes(size = 3, color = locality)) + scale_colour_manual(values = c("yellow2","orange1", "chartreuse4", "red1"), guide = guide_legend(title = "Population", override.aes = list(size=4))) +   ggtitle(paste0(gene, "\n(", transcript, "), q value = ", qval)) + guides(size=FALSE) + theme_bw()
 

  ggsave(paste0("colorgenepopulation-figures/", gene, "-", transcript, ".png"), width = 6.81, height = 3.99)
}


# write.csv(colorgenes_pop, "imitator_population_color_gene_stats.csv")
write.csv(pop_lrt_colors, "imitator_population_significant_color_gene_stats.csv")
write.csv(pop_siggies, "imitator_population_significant_genes.csv")

GO_pop_siggies <- dplyr::filter(pop_siggies, full_gene_name != "NA")
write.csv(GO_pop_siggies, "imitator_population_significant_genes_GO.csv")

significant_population_colorgenes <- unique(pop_lrt_colors$gene_name)

sopop <- sleuth_wt(sopop, '(Intercept)')
sopop <- sleuth_wt(sopop, 'localitySauce')
sopop <- sleuth_wt(sopop, 'localityTarapoto')
sopop <- sleuth_wt(sopop, 'localityVaradero')
pop_wt_results <- sleuth_results(sopop, '(Intercept)', test_type = "wt", which_model = "full",
  rename_cols = TRUE, show_all = TRUE)

```




Looks like there are 8,744 significant transcripts (q val < 0.05) between the populations here.

```{r}
locality <- samples$locality

notime_design <- model.matrix(formula( ~ locality + ns(week, df = 3):locality +lane))
notimeorpop_design <- model.matrix(formula( ~ ns(week, df = 3):locality +lane))

new_so <- sleuth_prep(samples,  num_cores = 6, target_mapping = anno)

new_so <- sleuth_fit(new_so, formula = notime_design, fit_name = "notime")
new_so <- sleuth_fit(new_so, formula = notimeorpop_design, fit_name = "notimepop")

models(new_so)
newso_lrt <- sleuth_lrt(new_so, "notime", "notimepop")
newso_lrt_results <- sleuth_results(newso_lrt, 'notime:notimepop', test_type = 'lrt')
table(newso_lrt_results[,"qval"] < 0.05) 

## THS TABLE IS ALL NAS! BLERGH.
```



```{r, eval = FALSE}

full_design <- model.matrix(formula( ~ ns(week, df = 3) + locality + ns(week, df = 3):locality +lane))
nopop_design <- model.matrix(formula( ~ ns(week, df = 3)  + ns(week, df = 3):locality +lane))
notime_design <- model.matrix(formula( ~ locality + ns(week, df = 3):locality +lane))
nointer_design <- model.matrix(formula( ~ ns(week, df = 3) + locality  +lane))


so.int <- sleuth_prep(samples,  num_cores = 6, target_mapping = biggie)

so.int <- sleuth_fit(so.int, formula = full_design, fit_name = "full")
so.int <- sleuth_fit(so.int, formula = nopop_design, fit_name = "nopop")


#so.int <- sleuth_fit(so, formula = ~  lane, fit_name = "reduced")


# No week in the model
models(so.int)
nopop_lrt <- sleuth_lrt(so.int, "full", "nopop")
nopop_lrt_results <- sleuth_results(nopop_lrt, 'full:nopop', test_type = 'lrt')
table(nopop_lrt_results[,"qval"] < 0.05) ### Produces an NA table

# No morph in the model
so.int <- sleuth_fit(so.int, formula = notime_design, fit_name = "noweek")
models(so.int)
noweek_lrt <- sleuth_lrt(so.int, "full", "noweek")
noweek_lrt_results <- sleuth_results(noweek_lrt, 'full:noweek', test_type = 'lrt')
table(noweek_lrt_results[,"qval"] < 0.05) ### Produces 15,754 DE transcripts

# No interaction in the model
so.int <- sleuth_fit(so.int, formula = nointer_design, fit_name = "nointer")
models(so.int)
nointer_lrt <- sleuth_lrt(so.int, "full", "nointer")
nointer_lrt_results <- sleuth_results(nointer_lrt, 'full:nointer', test_type = 'lrt')
table(nointer_lrt_results[,"qval"] < 0.05) ### Produces an NA table

```




```{r, eval = FALSE}

# All of these tables are NAs....





full2_design <- model.matrix(formula( ~ ns(week, df = 3) + locality +lane))
nopop2_design <- model.matrix(formula( ~ ns(week, df = 3) + lane))
notime2_design <- model.matrix(formula( ~ locality  +lane))

so.int2 <- sleuth_prep(samples,  num_cores = 6, target_mapping = biggie)

so.int2 <- sleuth_fit(so.int2, formula = full2_design, fit_name = "full2")
so.int2 <- sleuth_fit(so.int2, formula = nopop2_design, fit_name = "nopop2")



# No morph in the model
models(so.int2)
nopop2_lrt <- sleuth_lrt(so.int2, "full2", "nopop2")
nopop2_lrt_results <- sleuth_results(nopop2_lrt, 'full2:nopop2', test_type = 'lrt')
table(nopop2_lrt_results[,"qval"] < 0.05) ### Produces an NA table

# No week in the model
so.int2 <- sleuth_fit(so.int2, formula = notime2_design, fit_name = "noweek2")
models(so.int2)
noweek2_lrt <- sleuth_lrt(so.int2, "full2", "noweek2")
noweek2_lrt_results <- sleuth_results(noweek2_lrt, 'full2:noweek2', test_type = 'lrt')
table(noweek2_lrt_results[,"qval"] < 0.05) ### Produces an NA table



```




```{r, eval = FALSE}

# All of these tables are NAs....



locality <- samples$locality

full_design <- model.matrix(formula( ~ week + locality +lane))
nopop_design <- model.matrix(formula( ~ week + lane))
notime_design <- model.matrix(formula( ~ locality  +lane))

so <- sleuth_fit(so, formula = full_design, fit_name = "full")
so <- sleuth_fit(so, formula = nopop_design, fit_name = "nopop")
#so <- sleuth_fit(so, full_model = spline_design)
models(so)
so_lrt <- sleuth_lrt(so, "full", "nopop")
# so_wt <- sleuth_wt(so, "reduced", "full")
# Ok I don't know why that doesn't actually work....

lrt_results <- sleuth_results(so_lrt, 'full:nopop', test_type = 'lrt')
table(lrt_results[,"qval"] < 0.05)


so <- sleuth_fit(so, formula = notime_design, fit_name = "notime")
#so <- sleuth_fit(so, full_model = spline_design)
models(so)
so_lrt2 <- sleuth_lrt(so, "full", "notime")
# so_wt <- sleuth_wt(so, "reduced", "full")
# Ok I don't know why that doesn't actually work....

lrt_results2 <- sleuth_results(so_lrt2, 'full:notime', test_type = 'lrt')
table(lrt_results2[,"qval"] < 0.05)
```


Getting the overlap between the two:

```{r}

overlap <- lrt_colors %>% filter(target_id %in% pop_lrt_colors$target_id)
dim(overlap)

no_overlap <- lrt_colors %>% filter(!target_id %in% pop_lrt_colors$target_id)
dim(no_overlap)


```

Code to make figures about GO data from Pantherdb.org.

```{r}
# read in the data from Panther
bio <- read.csv("panther/panther-biologicalprocesses.csv")
cell <- read.csv("panther/panther-cellularcomponent.csv")
mol <- read.csv("panther/panther-molecularfunction.csv")

# make a theme
pietheme <- theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.grid  = element_blank())

# Get the # of pie slices for each, in order to set a color palette that doesn't look  like a 4 year old just squirted all the paint colors and 'finger painted' by smearing it everywhere
colourCountb = length(unique(bio$Category_name))
colourCountc = length(unique(cell$Category_name))
colourCountm = length(unique(mol$Category_name))
getPalette = colorRampPalette(brewer_pal(palette = "Set1")(9))

# Make and save a pie chart and bar chart for each
bp <- ggplot(bio, aes(x="", y=Genes, fill=Category_name)) + geom_bar(width = 1, stat = "identity")
bp <- bp + coord_polar("y") + theme_minimal() + ylab("Biological processes") + xlab("") + labs(fill="Category")  + pietheme +   scale_fill_manual(values = getPalette(colourCountb)) 
bp
ggsave("panther/biologicalprocesses-pie.png", width = 6.81, height = 3.99, dpi = 600)


bp1 <- ggplot(bio, aes(x="", y=Genes, fill=Category_name)) + geom_bar(width = 1, stat = "identity")
bp1 <- bp1 + theme_minimal() + ylab("Biological processes") + xlab("") + labs(fill="Category")  + pietheme +  scale_fill_canva(aes(x="", y=Genes, fill=Category_name), palette = "Cool blues") 
bp1
ggsave("panther/biologicalprocesses-bar.png", width = 6.81, height = 3.99, dpi = 600)

# Cellular processes pie chart
bp2 <- ggplot(cell, aes(x="", y=Genes, fill=Category_name)) + geom_bar(width = 1, stat = "identity")
bp2 <- bp2 + coord_polar("y") + theme_minimal() + ylab("Cellular component") + xlab("") + labs(fill="Category")  + pietheme +   scale_fill_manual(values = getPalette(colourCountc))
bp2
ggsave("panther/cellularcomponent-pie.png", width = 6.81, height = 3.99, dpi = 600)

# molecular function pie chart
bp3 <- ggplot(mol, aes(x="", y=Genes, fill=Category_name)) + geom_bar(width = 1, stat = "identity")
bp3 <- bp3 + coord_polar("y") + theme_minimal() + ylab("Molecular function") + xlab("") + labs(fill="Category")  + pietheme +   scale_fill_manual(values = getPalette(colourCountm))
bp3
ggsave("panther/molecularfunction-pie.png", width = 6.81, height = 3.99, dpi = 600)



# Produce the same plots as above, but just make them bar charts
# Biological function
# bio <-  bio[order(-bio$Genes),]
bio$Category_name <- factor(bio$Category_name, levels = bio$Category_name[order(bio$Genes)])
bp4 <- ggplot(bio, aes(x=Category_name, y=Genes)) + geom_bar(width = 1, stat = "identity") 
bp4 <- bp4 + coord_flip() + ylab("Number of genes") + xlab("Biological processes") + labs(fill="Category") + theme_bw()   
bp4
ggsave("panther/biologicalprocesses-bar.png", width = 6.81, height = 3.99, dpi = 600)

# Cellular processes
cell$Category_name <- factor(cell$Category_name, levels = cell$Category_name[order(cell$Genes)])
bp5 <- ggplot(cell, aes(x=Category_name, y=Genes)) + geom_bar(width = 1, stat = "identity")
bp5 <- bp5 + coord_flip() + ylab("Number of genes") + xlab("Cellular processes") + labs(fill="Category") + theme_bw()   
bp5
ggsave("panther/Cellularprocesses-bar.png", width = 6.81, height = 3.99, dpi = 600)

# Molecular function
mol$Category_name <- factor(mol$Category_name, levels = mol$Category_name[order(mol$Genes)])
bp6 <- ggplot(mol, aes(x=Category_name, y=Genes)) + geom_bar(width = 1, stat = "identity")
bp6 <- bp6 + coord_flip() + ylab("Number of genes") + xlab("Molecular function") + labs(fill="Category") + theme_bw()   
bp6
ggsave("panther/molecularfunction-bar.png", width = 6.81, height = 3.99, dpi = 600)

# Combine the three boxplots
com <- grid.arrange(bp4, bp5, bp6, nrow = 3)
com
ggsave("panther/combinedbarplots.png", com, width = 6.81, height = 12, dpi = 600)
```




General information here:
```{r}
print("Number of differentially expressed transcripts between time points:")
table(lrt_results[,"qval"] < 0.05)

print("Number of differentially expressed candidate color genes between time points:")
dim(lrt_colors)

print("Unique color genes differentiall expressed between time points (full annotation only):")
length(unique(lrt_colors$full_gene_name)) -1

print("Number of differentially expressed transcripts between populations:")
table(pop_lrt_results[,"qval"] < 0.05)

print("Number of differentially expressed candidate color genes between populations:")
dim(pop_lrt_colors)

print("Unique color genes differentiall expressed between populations (full annotation only):")
length(unique(pop_lrt_colors$full_gene_name)) -1

print("Number of differentially expressed transcripts both over time and between populations:")
dim(overlap)

print("The genes differentially expressed across both time and populations:")
print(overlap$xen_gene_name)
```


Load modified heatmap code from the Sleuth package. I probably won't actually use this, but it could be helpful.
```{r}
plot_transcript_heatmap <- function(obj,
  transcripts,
  units = 'tpm',
  trans = 'log',
  offset = 1) {

  # units <- check_quant_mode(obj, units)

  if(!all(transcripts %in% obj$obs_norm$target_id)) {
    stop("Couldn't find the following transcripts: ",
      paste(transcripts[!(transcripts %in% obj$obs_norm$target_id)], collapse = ", "),
      "\n\tIt is highly likely that some of them were filtered out.")
  }

  tabd_df <- obj$obs_norm[obj$obs_norm$target_id %in% transcripts, ]
  
  if (units == 'tpm') {
    tabd_df <- dplyr::select(tabd_df, target_id, sample, tpm)
    tabd_df <- reshape2::dcast(tabd_df, target_id ~sample, value.var = 'tpm')
  } else if (units == 'est_counts') {
    tabd_df <- dplyr::select(tabd_df, target_id, sample, est_counts)
    tabd_df <- reshape2::dcast(tabd_df, target_id ~sample, value.var = 'est_counts')
  } else {
    stop("Didn't recognize the following unit: ", units)
  }

  rownames(tabd_df) <- tabd_df$target_id
  tabd_df$target_id <- NULL

  p <- NULL
  if (nchar(trans) > 0 && !is.null(trans)) {
    tFunc <- eval(parse(text = trans))
    p <- ggPlotExpression(as.matrix(tFunc(tabd_df + offset)), clustRows = FALSE)
  } else {
    p <- ggPlotExpression(as.matrix(tabd_df), clustRows = FALSE)
  }

  p
}
ggPlotExpression <- function(exMat, clustRows = TRUE, clustCols = TRUE,
                             rowNames = TRUE, colNames = TRUE) {
    if (is(exMat, 'matrix')) {
        exMat <- as.matrix(exMat)
        stopifnot(class(exMat) == 'matrix')
    }
    exMat <- t(exMat)
    rowOrder <- 1:nrow(exMat)
    colOrder <- 1:ncol(exMat)
    if (clustRows)
        rowOrder <- orderByDendrogram(exMat)
    if (clustCols)
        colOrder <- orderByDendrogram(t(exMat))
    exMat <- exMat[rowOrder, colOrder]
    meltMat <- reshape2::melt(exMat, varnames = c("x", "y"))
    breaksM <- round(seq(min(meltMat$value, na.rm = T), max(meltMat$value, na.rm = T),
                         length.out = 10), 3)
                         #print(rownames(exMat))
    if (is.null(colnames(exMat)))
        colnames(exMat) <- 1:ncol(exMat)
    meltMat$y <- factor(meltMat$y, levels = colnames(exMat))
    meltMat$x <- factor(meltMat$x, levels = rownames(exMat))
    shortsamples <- samples[,c(1,6)]
    colnames(shortsamples)[1] <- "x"
   meltMat <- dplyr::left_join(meltMat, shortsamples, by = x)
    write.csv(meltMat, "ggplotorder.csv")
    p <- ggplot(meltMat, aes(x, y, fill = value))
    p <- p + geom_tile() + scale_fill_gradientn(colours = heat.colors(20),
          guide = guide_legend(title = "Expression: ",
                               reverse = T, size = 14))
    p <- p + theme_bw() + theme(legend.text = element_text(size = 14),
     legend.title = element_text(size = 14),
     legend.direction = 'vertical',
     legend.position = 'right',
     legend.background = element_rect(colour = "black", size = 0.5, linetype = 1),
     axis.title = element_blank())
    if (rowNames)
        p <- p + theme(axis.text.x = element_text(angle = 90, size = 14))
    else
        p <- p + theme(axis.text.x = element_text(size = 0))

    if (colNames)
        p <- p + theme(axis.text.y = element_text(size = 14))
    else
        p <- p + theme(axis.text.y = element_text(size = 0))

    p
    #list(plot = p, rowOrder = rowOrder, colOrder = colOrder)
}
orderByDendrogram <- function(mat) {
    hc <- hclust(dist(mat))
    dc <- as.dendrogram(hc)
    order.dendrogram(dc)
}
```


Make a pteridine heatmap via the Sleuth code; again I probably won't use this.

```{r, eval = FALSE}
# load pteridine transcripts 
pterinfo <- read.csv("heatmapdocs/pteridinegenes.csv")
pterinfo <- pterinfo[,-1]



ptheat <- plot_transcript_heatmap(sopop, pterinfo$target_id, units = "est_counts", trans = "log") + labs(title = "Pteridine genes") + theme(plot.title = element_text(hjust = 0))  
ptheat
melteddf <- read.csv("ggplotorder.csv")
colnames(melteddf)[3] <- "target_id"
melteddf <- dplyr::left_join(melteddf, pterinfo, by = "target_id")
melteddf <- melteddf[,c(3,5)]
ptergenes <- dplyr::distinct(melteddf)
ptheat <- ptheat + scale_y_discrete(labels = ptergenes$ptergenes)
ptheat
ggsave("heatmapdocs/pteridinemodifiedsleuthcodeheatmap.png", width = 8.84, height = 8.84)

```

Now, make heatmaps that are arranged by population and time point on the x axis, and alphabetically on the y axis.

```{r}
# get only the sample info I want:
samples2 <- samples[,c(1,6)]

# load pteridine transcripts, which I've made and put in a spreadsheet
pterinfo <- read.csv("heatmapdocs/pteridinegenes.csv")
pterinfo <- pterinfo[,-1]

# extract the data from the population model
pterdf  <- sopop$obs_norm[sopop$obs_norm$target_id %in% pterinfo$target_id, ]
# append group info (ie, pop x time)
pterdf <- dplyr::left_join(pterdf, samples2, by = "sample")
# append data from sleuth model
pterdf <- dplyr::left_join(pterdf, pterinfo, by = "target_id")

# make a new df, then take the offset log of the counts
logpterdf <- pterdf
logpterdf$est_counts <- log(pterdf$est_counts + 1)


ggplot(logpterdf, aes(sample, ptergenes)) +
    geom_tile(aes(fill = est_counts)) + scale_fill_gradientn(colours = heat.colors(20),
          guide = guide_legend(title = "Expression: ",
                               reverse = T, size = 14)) + 
  scale_x_discrete(labels = sort(group)) + ylab("Genes ") +
    theme_bw() + theme(legend.text = element_text(size = 14),
     legend.title = element_text(size = 14),
     legend.direction = 'vertical',
     legend.position = 'right',
     legend.background = element_rect(colour = "black", size = 0.5, linetype = 1),
     axis.title = element_blank(), axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(fill = "Expression level")
ggsave("heatmapdocs/pteridineheatmapmodifiedsleuthcode.png", width = 8.84, height = 6.45)

ptertranscripts <- pterinfo[order(pterinfo$target_id),]

ggplot(logpterdf, aes(sample, target_id)) +
  geom_tile(aes(fill = est_counts), color = "white") +
  scale_fill_gradient(low = "red3", high = "yellow") +
  scale_x_discrete(labels = sort(group)) + ylab("Genes ") + xlab("") + labs(title = "Pteridine genes") +
  scale_y_discrete(labels = ptertranscripts$ptergenes) +
  theme(legend.title = element_text(size = 10),
        legend.text = element_text(size = 12),
        plot.title = element_text(size=16),
        axis.title=element_text(size=14,face="bold"),
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(fill = "Expression level")


ggsave("heatmapdocs/pteridineheatmap.png", width = 8.84, height = 6.45)
```

Heatmaps for days.

```{r}
# load melanin transcripts 
melinfo <- read.csv("heatmapdocs/melanophoregenes.csv")

meldf  <- sopop$obs_norm[sopop$obs_norm$target_id %in% melinfo$target_id, ]
meldf <- dplyr::left_join(meldf, samples2, by = "sample")
meldf <- dplyr::left_join(meldf, melinfo, by = "target_id")
logmeldf <- meldf
logmeldf$est_counts <- log(meldf$est_counts + 1)

meltranscripts <- melinfo[order(melinfo$target_id),]


ggplot(logmeldf, aes(sample, target_id)) +
  geom_tile(aes(fill = est_counts), color = "white") +
  scale_fill_gradient(low = "red3", high = "yellow") +
  scale_x_discrete(labels = sort(group)) + ylab("Genes ") + xlab("") + labs(title = "Melanic genes") +
  scale_y_discrete(labels = meltranscripts$mel_gene_name) +
  theme(legend.title = element_text(size = 10),
        legend.text = element_text(size = 12),
        plot.title = element_text(size=16),
        axis.title=element_text(size=14,face="bold"),
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(fill = "Expression level")


ggsave("heatmapdocs/melanophoreheatmap.png", width = 8.84, height = 6.45)


# Iridophore genes
irinfo <- read.csv("heatmapdocs/iridophoregenes.csv")

irdf  <- sopop$obs_norm[sopop$obs_norm$target_id %in% irinfo$target_id, ]
irdf <- dplyr::left_join(irdf, samples2, by = "sample")
irdf <- dplyr::left_join(irdf, irinfo, by = "target_id")
logirdf <- irdf
logirdf$est_counts <- log(irdf$est_counts + 1)

irtranscripts <- irinfo[order(irinfo$target_id),]

ggplot(logirdf, aes(sample, target_id)) +
  geom_tile(aes(fill = est_counts), color = "white") +
  scale_fill_gradient(low = "red3", high = "yellow") +
  scale_x_discrete(labels = sort(group)) + ylab("Genes ") + xlab("") + labs(title = "Iridophore genes") +
  scale_y_discrete(labels = irtranscripts$iridophore_gene_name) +
  theme(legend.title = element_text(size = 10),
        legend.text = element_text(size = 12),
        plot.title = element_text(size=16),
        axis.title=element_text(size=14,face="bold"),
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(fill = "Expression level")


ggsave("heatmapdocs/iridophoreheatmap.png", width = 8.84, height = 6.45)

```



